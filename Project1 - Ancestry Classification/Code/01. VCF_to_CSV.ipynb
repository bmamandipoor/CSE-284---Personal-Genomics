{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e259061a",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6949ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cyvcf2 import VCF\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d20aca9",
   "metadata": {},
   "source": [
    "### Path to Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2ed20fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_path = './public/1000Genomes/'\n",
    "csv_output_dir = './Data/csv/'\n",
    "parquet_output_dir = './Data/parquet/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d6a391",
   "metadata": {},
   "source": [
    "### Read VCF File and Convert to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b32046d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_vcf_files(directory):\n",
    "\n",
    "    prefix = \"1000G_chr\"\n",
    "    suffix = \"_pruned.vcf.gz\"\n",
    "    \n",
    "    vcf_files = []\n",
    "    \n",
    "    for file in os.listdir(directory):\n",
    "        if file.startswith(prefix) and file.endswith(suffix):\n",
    "            chr_num = file[len(prefix):-len(suffix)].replace(\"chr\", \"\")\n",
    "            if chr_num.isdigit() and 1 <= int(chr_num) <= 22:\n",
    "                vcf_files.append(os.path.join(directory, file))\n",
    "    \n",
    "    return vcf_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "355840a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_vcf_files = list_vcf_files(vcf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9880130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_vcf_write_csv(vcf_path, output_dir):\n",
    "    \n",
    "    vcf_reader = VCF(vcf_path)\n",
    "    sample_ids = vcf_reader.samples\n",
    "    \n",
    "    snp_data = {'Person_ID': sample_ids}\n",
    "\n",
    "    for record in vcf_reader:\n",
    "        if record.ID:  \n",
    "            snp_id = record.ID \n",
    "            genotypes = []  \n",
    "            for gt in record.genotypes:  \n",
    "                if gt[0] == -1 or gt[1] == -1:  \n",
    "                    genotypes.append(np.nan)  \n",
    "                else:\n",
    "                    genotypes.append(gt[0] + gt[1])\n",
    "            if len(genotypes) == len(sample_ids):\n",
    "                snp_data[snp_id] = genotypes\n",
    "        else:\n",
    "            continue  \n",
    "            \n",
    "    df = pd.DataFrame(snp_data)\n",
    "    \n",
    "    chromosome_number = os.path.basename(vcf_path).split('_')[1]\n",
    "    output_file = os.path.join(output_dir, f\"{chromosome_number}.csv\")\n",
    "    \n",
    "    df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7b5bc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for vcf_file in list_of_vcf_files:\n",
    "    read_vcf_write_csv(vcf_file, csv_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5899a98",
   "metadata": {},
   "source": [
    "### Read CSV File and Convert to Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdf30fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_parquet(source_dir, target_dir, file_pattern='chr*.csv'):\n",
    "\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.makedirs(target_dir)\n",
    "\n",
    "    for file_name in os.listdir(source_dir):\n",
    "        if fnmatch.fnmatch(file_name, file_pattern):\n",
    "            csv_file_path = os.path.join(source_dir, file_name)\n",
    "            parquet_file_path = os.path.join(target_dir, file_name.replace('.csv', '.parquet'))\n",
    "\n",
    "            df = pd.read_csv(csv_file_path)\n",
    "            table = pa.Table.from_pandas(df)\n",
    "            pq.write_table(table, parquet_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbe35ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_to_parquet(csv_output_dir, parquet_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5751579",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b18eed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
